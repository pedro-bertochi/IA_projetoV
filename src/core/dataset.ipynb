{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.processar_imagens import combinar_imagens\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParImageGenerator(Sequence):\n",
    "    def __init__(self, pasta, batch_size=32):\n",
    "        self.imagens = []\n",
    "        self.labels = []\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        for classe in ['boa', 'ruim']:\n",
    "            caminho = os.path.join(pasta, classe)\n",
    "            arquivos = sorted(os.listdir(caminho))\n",
    "            pares = [(arquivos[i], arquivos[i + 1]) for i in range(0, len(arquivos), 2)]\n",
    "            for par in pares:\n",
    "                self.imagens.append((\n",
    "                    os.path.join(caminho, par[0]),\n",
    "                    os.path.join(caminho, par[1])\n",
    "                ))\n",
    "                self.labels.append(1 if classe == 'boa' else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagens) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.imagens[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        imagens_processadas = [combinar_imagens(p1, p2) for p1, p2 in batch_x]\n",
    "        return np.array(imagens_processadas) / 255.0, np.array(batch_y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
