#!/usr/bin/env python
# coding: utf-8

# In[65]:


import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from sklearn.model_selection import train_test_split
from PIL import Image


# In[66]:


try:
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        # Configura a memÃ³ria da GPU para crescer dinamicamente.
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU(s) detectada(s) e configurada(s) para uso dinÃ¢mico de memÃ³ria: {gpus}")
        print("TensorFlow utilizarÃ¡ a(s) GPU(s) disponÃ­vel(is) para aceleraÃ§Ã£o.")
    else:
        print("âŒ Nenhuma GPU compatÃ­vel com CUDA detectada. O TensorFlow serÃ¡ executado na CPU.")
        print("Continuando a execuÃ§Ã£o na CPU.")
except RuntimeError as e:
    print(f"âŒ Erro ao configurar GPU: {e}")
    print("O TensorFlow serÃ¡ executado na CPU devido ao erro na configuraÃ§Ã£o da GPU.")


# In[67]:


DATA_DIR = 'C:\\cod\\python\\AI\\image\\treinamento'
MODEL_SAVE_DIR = 'C:\\cod\\python\\AI\\model_novo' # Novo diretÃ³rio para nÃ£o conflitar com o projeto existente
LOGS_SAVE_DIR = 'C:\\cod\\python\\AI\\logs_novo'   # Novo diretÃ³rio para logs
RESULTS_SAVE_DIR = 'C:\\cod\\python\\AI\\results_novo'


# In[68]:


# ParÃ¢metros de Imagem
IMAGE_HEIGHT = 224
IMAGE_WIDTH = 224
NUM_CHANNELS = 3 # RGB


# In[69]:


BATCH_SIZE = 16 # Aumentei o batch size para aproveitar melhor a GPU
EPOCHS_PHASE1 = 5  # Ã‰pocas para a fase 1 (treinar apenas o cabeÃ§alho)
EPOCHS_PHASE2 = 10 # Ã‰pocas para a fase 2 (fine-tuning das Ãºltimas camadas)
LEARNING_RATE_PH1 = 1e-3 # LR maior para a fase 1 (cabeÃ§alho)
LEARNING_RATE_PH2 = 1e-5 # LR menor para a fase 2 (fine-tuning)
ES_PATIENCE = 5


# In[70]:


# Camadas da ResNet50 a descongelar na Fase 2
# 0: Congela toda a base. -1: Descongela toda a base. >0: Descongela as Ãºltimas N camadas.
UNFREEZE_LAST_N_LAYERS_PH2 = 3 # Exemplo: descongelar as Ãºltimas 3 camadas da ResNet50 na Fase 2


# In[71]:


# ParÃ¢metros de DivisÃ£o de Dados
TRAIN_RATIO = 0.70 # 70% para treino
VAL_RATIO = 0.15   # 15% para validaÃ§Ã£o
TEST_RATIO = 0.15  # 15% para teste
GLOBAL_RANDOM_STATE = 42 # Para reprodutibilidade


# In[72]:


# Nomes das classes (a ordem deve corresponder aos rÃ³tulos numÃ©ricos 0 e 1)
# 'ruim' corresponde ao rÃ³lo 0, 'boa' corresponde ao rÃ³tulo 1
CLASS_NAMES = ["solda_ruim", "solda_boa"]

# --- CriaÃ§Ã£o de DiretÃ³rios ---
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
os.makedirs(LOGS_SAVE_DIR, exist_ok=True)
os.makedirs(RESULTS_SAVE_DIR, exist_ok=True)


# In[73]:


# --- 1. FunÃ§Ã£o para Carregar Caminhos das Imagens e RÃ³tulos (Imagens Ãšnicas) ---
def load_image_paths_and_labels_single_image(data_dir):
    """
    Carrega os caminhos das imagens e seus rÃ³tulos para imagens Ãºnicas.
    Assume a estrutura: data_dir/boa/img_x.jpg, data_dir/ruim/img_y.jpg
    """
    all_paths = []
    all_labels = []

    # A ordem das classes aqui define qual rÃ³tulo numÃ©rico (0 ou 1) elas receberÃ£o
    # 'ruim' serÃ¡ 0, 'boa' serÃ¡ 1
    for i, class_name_folder in enumerate(['ruim', 'boa']): # Iterar sobre as pastas
        class_path = os.path.join(data_dir, class_name_folder)
        if not os.path.isdir(class_path):
            print(f"AVISO: DiretÃ³rio de classe '{class_path}' nÃ£o encontrado. Pulando.")
            continue

        # Lista os arquivos de imagem
        files = sorted([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

        for file_name in files:
            path = os.path.join(class_path, file_name)
            all_paths.append(path)
            all_labels.append(i) # RÃ³tulo numÃ©rico: 0 para 'ruim', 1 para 'boa'

    return all_paths, all_labels


# In[74]:


# --- FunÃ§Ã£o auxiliar para imprimir erros de forma legÃ­vel dentro do tf.data pipeline ---
def _print_debug_error(image_path_tensor, error_message_tensor):
    """Auxiliar para imprimir erros com caminho da imagem resolvido."""
    # tf.py_function passa tensores, precisamos convertÃª-los para strings Python
    image_path_str = image_path_tensor.numpy().decode('utf-8')
    error_message_str = error_message_tensor.numpy().decode('utf-8')
    print(f"DEBUG_ERROR: Erro ao processar imagem '{image_path_str}': {error_message_str}. Retornando imagem dummy.")
    # tf.py_function precisa retornar algo, mesmo que nÃ£o seja usado.
    return 0 # Valor dummy


# In[ ]:


# --- 2. FunÃ§Ã£o para PrÃ©-processar e Augmentar Imagens Ãšnicas (para tf.data.Dataset) ---
def preprocess_and_augment_single_image(image_path, label, augment=False):
    """
    Carrega, redimensiona e prÃ©-processa uma Ãºnica imagem.
    Aplica aumento de dados se 'augment' for True.
    """
    try:
        img_bytes = tf.io.read_file(image_path)
        img = tf.image.decode_jpeg(img_bytes, channels=NUM_CHANNELS)
        img.set_shape([None, None, NUM_CHANNELS])  # Define o shape inicial como desconhecido

        # --- DEBUG: Verifica o shape APÃ“S a decodificaÃ§Ã£o ---
        # Converte o caminho do tensor para string para usar nas mensagens de erro
        image_path_str_tensor = tf.strings.format("{}", image_path)

        # Verifica se o tensor da imagem decodificada tem um shape vÃ¡lido e nÃ£o estÃ¡ vazio
        if tf.reduce_prod(tf.shape(img)) == 0 or tf.rank(img) != 3:
            # Chama a funÃ§Ã£o auxiliar Python para imprimir o erro com o caminho resolvido
            tf.py_function(
                _print_debug_error,
                [image_path, tf.constant("Decode_image resultou em tensor vazio ou com shape invÃ¡lido ('images' contains no shape).")],
                tf.int32 # O tipo de retorno da funÃ§Ã£o Python
            )
            return tf.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), dtype=tf.float32), tf.cast(label, tf.float32)

        # Garante o nÃºmero correto de canais
        if tf.shape(img)[2] != NUM_CHANNELS:
            tf.py_function(
                _print_debug_error,
                [image_path, tf.constant(f"NÃºmero de canais incorreto ({tf.shape(img)[2]}), esperado {NUM_CHANNELS}.")],
                tf.int32
            )
            return tf.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), dtype=tf.float32), tf.cast(label, tf.float32)

        img = tf.image.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))
        img = tf.image.convert_image_dtype(img, tf.float32)

        # Aplicar aumento de dados
        if augment:
            img = tf.image.random_flip_left_right(img)
            img = tf.image.random_brightness(img, max_delta=0.1)
            img = tf.image.random_contrast(img, lower=0.9, upper=1.1)

        return img, tf.cast(label, tf.float32)

    except tf.errors.InvalidArgumentError as e:
        # Erro de argumento invÃ¡lido ao decodificar (formato de arquivo invÃ¡lido, etc.)
        tf.py_function(
            _print_debug_error,
            [image_path, tf.constant(f"tf.errors.InvalidArgumentError ao decodificar: {str(e)}")],
            tf.int32
        )
        return tf.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), dtype=tf.float32), tf.cast(label, tf.float32)
    except Exception as e:
        # Captura outros erros inesperados
        tf.py_function(
            _print_debug_error,
            [image_path, tf.constant(f"Erro inesperado no prÃ©-processamento: {str(e)}")],
            tf.int32
        )
        return tf.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), dtype=tf.float32), tf.cast(label, tf.float32)


# In[76]:


# --- 3. FunÃ§Ã£o para Criar o Modelo ResNet50 (para Imagens Ãšnicas) ---
def create_resnet_model_for_single_images(train_last_n_base_layers: int = 0):
    """
    Cria e compila o modelo ResNet50 adaptado para imagens Ãºnicas.

    Args:
        train_last_n_base_layers (int): NÃºmero de Ãºltimas camadas da base ResNet50
                                        a serem descongeladas e treinÃ¡veis.
                                        0: Congela toda a base (treina apenas o cabeÃ§alho).
                                        -1: Descongela toda a base.
                                        >0: Descongela as Ãºltimas N camadas.
    """
    # O input_shape agora Ã© (altura, largura, canais)
    input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)

    # Congela TODAS as camadas da base por padrÃ£o.
    base_model.trainable = False

    # Descongela as Ãºltimas N camadas da base, se o parÃ¢metro for > 0
    if train_last_n_base_layers is not None and train_last_n_base_layers > 0:
        num_base_layers = len(base_model.layers)
        start_unfreeze_idx = max(0, num_base_layers - train_last_n_base_layers)
        for layer in base_model.layers[start_unfreeze_idx:]:
            layer.trainable = True
        print(f"Modelo: Descongeladas as Ãºltimas {train_last_n_base_layers} camadas da base ResNet50.")
    elif train_last_n_base_layers is not None and train_last_n_base_layers < 0:
        # Descongela todas as camadas da base
        for layer in base_model.layers:
            layer.trainable = True
        print("Modelo: Descongeladas TODAS as camadas da base ResNet50.")
    else: # train_last_n_base_layers == 0
        print("Modelo: Todas as camadas da base ResNet50 estÃ£o congeladas (treinando apenas o cabeÃ§alho).")
    # Adiciona as camadas de topo (cabeÃ§alho de classificaÃ§Ã£o)
    x = GlobalAveragePooling2D()(base_model.output)
    x = Dense(128, activation='relu')(x)
    output = Dense(1, activation='sigmoid')(x) # SaÃ­da binÃ¡ria

    model = Model(inputs=base_model.input, outputs=output)

    # CompilaÃ§Ã£o serÃ¡ feita na funÃ§Ã£o de treinamento para permitir diferentes LRs por fase
    return model


# In[77]:


# --- 4. FunÃ§Ã£o para Criar Callbacks do TensorBoard ---
def create_tensorboard_callback(log_dir_base, sub_dir_name):
    """Cria e retorna um callback do TensorBoard."""
    log_dir = os.path.join(log_dir_base, sub_dir_name)
    os.makedirs(log_dir, exist_ok=True)
    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)
    print(f"Logs do TensorBoard serÃ£o salvos em: {os.path.abspath(log_dir)}")
    return tensorboard_callback


# In[78]:


# --- 5. FunÃ§Ã£o para Treinar uma Fase do Modelo ---
def train_model_phase(model, train_ds, val_ds, phase_name, epochs, learning_rate,
                      checkpoint_path, history_log_path, tensorboard_log_subdir, patience):
    """
    Executa uma fase de treinamento para o modelo.
    """
    print(f"\n--- Iniciando {phase_name} (LR: {learning_rate}, Ã‰pocas: {epochs}) ---")

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',
                                 save_best_only=True, verbose=1)
    early_stopping = EarlyStopping(monitor='val_loss', patience=patience,
                                   restore_best_weights=True, verbose=1)
    csv_logger = tf.keras.callbacks.CSVLogger(history_log_path, append=False)
    tensorboard_cb = create_tensorboard_callback(LOGS_SAVE_DIR, tensorboard_log_subdir)

    history = model.fit(
        train_ds,
        epochs=epochs,
        validation_data=val_ds,
        callbacks=[checkpoint, early_stopping, csv_logger, tensorboard_cb],
        verbose=1
    )
    print(f"--- {phase_name} concluÃ­da ---")
    return model


# In[79]:


# --- Bloco de ExecuÃ§Ã£o Principal ---
if __name__ == "__main__":
    print("Iniciando o script de treinamento de ResNet50 para solda (imagens Ãºnicas)...")

    # 1. Carregar caminhos das imagens e rÃ³tulos
    print("Carregando caminhos das imagens e rÃ³tulos...")
    all_image_paths, all_labels = load_image_paths_and_labels_single_image(DATA_DIR)
    print(f"Total de imagens encontradas: {len(all_image_paths)}")

    if not all_image_paths:
        print(f"âŒ Nenhuma imagem encontrada em '{DATA_DIR}'. Certifique-se de que as pastas 'boa' e 'ruim' existem e contÃªm imagens.")
        exit()

    # 2. Dividir os dados em Treino / ValidaÃ§Ã£o / Teste
    print("Dividindo os dados em Treino / ValidaÃ§Ã£o / Teste...")
    # Primeiro, separamos o Teste
    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(
        all_image_paths, all_labels, test_size=TEST_RATIO, random_state=GLOBAL_RANDOM_STATE,
        stratify=all_labels
    )
    # Segundo, separamos Treino e ValidaÃ§Ã£o do restante
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        train_val_paths, train_val_labels, test_size=VAL_RATIO / (TRAIN_RATIO + VAL_RATIO), # ProporÃ§Ã£o de val no conjunto train_val
        random_state=GLOBAL_RANDOM_STATE,
        stratify=train_val_labels
    )

    print(f"Imagens de Treino: {len(train_paths)}")
    print(f"Imagens de ValidaÃ§Ã£o: {len(val_paths)}")
    print(f"Imagens de Teste: {len(test_paths)}")

    # 3. Criar os tf.data.Dataset
    print("Criando pipelines de dados (tf.data.Dataset)...")
    # Conjunto de Treino (com aumento de dados)
    train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))
    train_ds = train_ds.map(lambda p, l: preprocess_and_augment_single_image(p, l, augment=True),
                            num_parallel_calls=tf.data.AUTOTUNE)
    train_ds = train_ds.shuffle(buffer_size=len(train_paths)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # Conjunto de ValidaÃ§Ã£o (sem aumento de dados)
    val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))
    val_ds = val_ds.map(lambda p, l: preprocess_and_augment_single_image(p, l, augment=False),
                        num_parallel_calls=tf.data.AUTOTUNE)
    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # Conjunto de Teste (sem aumento de dados)
    test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))
    test_ds = test_ds.map(lambda p, l: preprocess_and_augment_single_image(p, l, augment=False),
                        num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)


    # 4. Treinamento - FASE 1: Treinar apenas o cabeÃ§alho de classificaÃ§Ã£o
    print("\n--- INICIANDO FASE 1 DE TREINAMENTO (Treinar apenas o cabeÃ§alho) ---")
    model_phase1 = create_resnet_model_for_single_images(train_last_n_base_layers=0) # Congela toda a base
    trained_model_phase1 = train_model_phase(
        model=model_phase1,
        train_ds=train_ds,
        val_ds=val_ds,
        phase_name="Fase 1",
        epochs=EPOCHS_PHASE1,
        learning_rate=LEARNING_RATE_PH1,
        checkpoint_path=os.path.join(MODEL_SAVE_DIR, 'model_phase1_best.h5'),
        history_log_path=os.path.join(RESULTS_SAVE_DIR, 'history_phase1.csv'),
        tensorboard_log_subdir='phase_1',
        patience=ES_PATIENCE
    )

    # Carregar o melhor modelo da Fase 1 para a Fase 2 (garantir que Ã© o salvo pelo checkpoint)
    try:
        model_for_phase2 = load_model(os.path.join(MODEL_SAVE_DIR, 'model_phase1_best.h5'))
        print("âœ… Melhor modelo da Fase 1 carregado para a Fase 2.")
    except Exception as e:
        print(f"âŒ ERRO: NÃ£o foi possÃ­vel carregar o melhor modelo da Fase 1. Erro: {e}")
        print("A Fase 2 nÃ£o poderÃ¡ iniciar. Encerrando o script.")
        exit()


    # 5. Treinamento - FASE 2: Fine-tuning das Ãºltimas camadas da ResNet50
    print("\n--- INICIANDO FASE 2 DE TREINAMENTO (Fine-tuning das Ãºltimas camadas) ---")
    # Reconfigura o modelo para descongelar as Ãºltimas N camadas
    if hasattr(model_for_phase2.layers[0], 'layers'): # Verifica se a primeira camada Ã© a base ResNet50
        base_model_ph2 = model_for_phase2.layers[0]
        base_model_ph2.trainable = True # Garante que a base estÃ¡ treinÃ¡vel antes de congelar partes
        num_base_layers = len(base_model_ph2.layers)
        start_unfreeze_idx = max(0, num_base_layers - UNFREEZE_LAST_N_LAYERS_PH2)
        for layer in base_model_ph2.layers[start_unfreeze_idx:]:
            layer.trainable = True
        print(f"Modelo: Descongeladas as Ãºltimas {UNFREEZE_LAST_N_LAYERS_PH2} camadas da base ResNet50 para Fase 2.")
    else:
        print("AVISO: A primeira camada do modelo nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.")

    final_trained_model = train_model_phase(
        model=model_for_phase2, # Continua treinando o modelo da Fase 1
        train_ds=train_ds,
        val_ds=val_ds,
        phase_name="Fase 2",
        epochs=EPOCHS_PHASE2,
        learning_rate=LEARNING_RATE_PH2,
        checkpoint_path=os.path.join(MODEL_SAVE_DIR, 'model_final_best.h5'), # Salva o modelo final
        history_log_path=os.path.join(RESULTS_SAVE_DIR, 'history_phase2.csv'),
        tensorboard_log_subdir='phase_2',
        patience=ES_PATIENCE
    )


    # 6. AvaliaÃ§Ã£o Final no Conjunto de Teste
    print("\n--- AVALIAÃ‡ÃƒO FINAL NO CONJUNTO DE TESTE ---")
    test_loss, test_accuracy = final_trained_model.evaluate(test_ds, verbose=1)
    print(f"ðŸŽ‰ Resultado Final no Conjunto de Teste:")
    print(f"   Loss: {test_loss:.4f}")
    print(f"   Accuracy: {test_accuracy:.4f}")

    # Mapear a acurÃ¡cia para as classes
    # A acurÃ¡cia Ã© uma mÃ©trica geral, nÃ£o especÃ­fica de classe.
    # Para ver a performance por classe, precisarÃ­amos de metrics.Precision, metrics.Recall ou um classification_report.
    # Aqui, apenas indicamos a acurÃ¡cia geral e quais classes o modelo estÃ¡ classificando.
    print(f"   O modelo foi treinado para classificar entre: {CLASS_NAMES[0]} e {CLASS_NAMES[1]}")


    # Salvar resultados finais em um arquivo
    with open(os.path.join(RESULTS_SAVE_DIR, 'final_test_results.txt'), 'w') as f:
        f.write("--- Resultados Finais do Treinamento ---\n")
        f.write(f"Total de imagens: {len(all_image_paths)}\n")
        f.write(f"Imagens de Treino: {len(train_paths)}\n")
        f.write(f"Imagens de ValidaÃ§Ã£o: {len(val_paths)}\n")
        f.write(f"Imagens de Teste: {len(test_paths)}\n\n")
        f.write(f"Loss no Teste: {test_loss:.4f}\n")
        f.write(f"Accuracy no Teste: {test_accuracy:.4f}\n")
        f.write(f"Classes classificadas: {CLASS_NAMES[0]} (0) e {CLASS_NAMES[1]} (1)\n")
    print(f"Resultados finais salvos em: {os.path.abspath(os.path.join(RESULTS_SAVE_DIR, 'final_test_results.txt'))}")

    print("\nScript de treinamento concluÃ­do com sucesso!")

