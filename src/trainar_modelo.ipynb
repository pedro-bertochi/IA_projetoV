{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from core import criar_modelo, ParImageGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "os.makedirs('../model', exist_ok=True)\n",
    "os.makedirs('../results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando novo modelo...\n"
     ]
    }
   ],
   "source": [
    "# Caminho para salvar o modelo principal\n",
    "caminho_modelo = '../model/modelo_solda_resnet50.h5'\n",
    "\n",
    "# Carregar ou criar o modelo\n",
    "if os.path.exists(caminho_modelo):\n",
    "    print(\"Carregando modelo salvo...\")\n",
    "    modelo = tf.keras.models.load_model(caminho_modelo)\n",
    "else:\n",
    "    print(\"Criando novo modelo...\")\n",
    "    modelo = criar_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompilar com otimizador novo\n",
    "modelo.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 🔁 Carregar dados e dividir entre treino/validação\n",
    "# ============================================\n",
    "pasta = '../image/treinamento'\n",
    "if not os.path.exists(pasta):\n",
    "    raise FileNotFoundError(f\"Diretório {pasta} não encontrado.\")\n",
    "gen_temporario = ParImageGenerator(pasta, batch_size=1, augmentacao=False)\n",
    "dados = list(zip(gen_temporario.imagens, gen_temporario.labels))\n",
    "\n",
    "train_data, val_data = train_test_split(dados, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Criar geradores com dados separados\n",
    "train_gen = ParImageGenerator(pasta, train_data, batch_size=8, augmentacao=True)\n",
    "val_gen = ParImageGenerator(pasta, val_data, batch_size=8, augmentacao=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 📦 Callbacks: checkpoint + logger\n",
    "# ============================================\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../model/melhor_modelo.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "logger = CSVLogger('../results/historico_treinamento.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\finan\\OneDrive - Nimofast Brasil SA\\Área de Trabalho\\cod\\python\\AI\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "c:\\Users\\finan\\OneDrive - Nimofast Brasil SA\\Área de Trabalho\\cod\\python\\AI\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.3125 - loss: 0.7938 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.84821, saving model to ../model/melhor_modelo.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 72s/step - accuracy: 0.3750 - loss: 0.7972 - val_accuracy: 0.8482 - val_loss: 4.6962\n",
      "Epoch 2/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9688 - loss: 0.2694 \n",
      "Epoch 2: val_accuracy improved from 0.84821 to 0.85714, saving model to ../model/melhor_modelo.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 96s/step - accuracy: 0.9583 - loss: 0.3574 - val_accuracy: 0.8571 - val_loss: 21.5419\n",
      "Epoch 3/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9688 - loss: 0.0640\n",
      "Epoch 3: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22s/step - accuracy: 0.9583 - loss: 0.0832 - val_accuracy: 0.8571 - val_loss: 69.0150\n",
      "Epoch 4/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.2291\n",
      "Epoch 4: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 49s/step - accuracy: 0.8750 - loss: 0.2304 - val_accuracy: 0.8482 - val_loss: 241.1167\n",
      "Epoch 5/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8750 - loss: 1.3717\n",
      "Epoch 5: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 48s/step - accuracy: 0.8750 - loss: 1.7535 - val_accuracy: 0.8482 - val_loss: 475.4986\n",
      "Epoch 6/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9688 - loss: 0.4675 \n",
      "Epoch 6: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 50s/step - accuracy: 0.9583 - loss: 0.5667 - val_accuracy: 0.8571 - val_loss: 35066.8711\n",
      "Epoch 7/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.3327 \n",
      "Epoch 7: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 61s/step - accuracy: 0.7917 - loss: 0.3622 - val_accuracy: 0.8482 - val_loss: 2187371.7500\n",
      "Epoch 8/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 1.0000 - loss: 0.2889 \n",
      "Epoch 8: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 50s/step - accuracy: 1.0000 - loss: 0.2751 - val_accuracy: 0.8482 - val_loss: 2537165.5000\n",
      "Epoch 9/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.9688 - loss: 0.4205 \n",
      "Epoch 9: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 61s/step - accuracy: 0.9583 - loss: 0.5159 - val_accuracy: 0.8482 - val_loss: 31034098.0000\n",
      "Epoch 10/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - accuracy: 0.7500 - loss: 0.5167 \n",
      "Epoch 10: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 35s/step - accuracy: 0.7500 - loss: 0.5182 - val_accuracy: 0.8482 - val_loss: 267929712.0000\n",
      "Epoch 11/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9062 - loss: 1.1448\n",
      "Epoch 11: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40s/step - accuracy: 0.9167 - loss: 1.0380 - val_accuracy: 0.8482 - val_loss: 329946816.0000\n",
      "Epoch 12/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7812 - loss: 0.6668\n",
      "Epoch 12: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 36s/step - accuracy: 0.7917 - loss: 0.6386 - val_accuracy: 0.8482 - val_loss: 172834080.0000\n",
      "Epoch 13/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8750 - loss: 0.5100  \n",
      "Epoch 13: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27s/step - accuracy: 0.8750 - loss: 0.4978 - val_accuracy: 0.8571 - val_loss: 64314468.0000\n",
      "Epoch 14/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23s/step - accuracy: 0.9375 - loss: 0.3321 \n",
      "Epoch 14: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66s/step - accuracy: 0.9167 - loss: 0.3512 - val_accuracy: 0.8571 - val_loss: 43039316.0000\n",
      "Epoch 15/15\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.7188 - loss: 0.8170 \n",
      "Epoch 15: val_accuracy did not improve from 0.85714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 43s/step - accuracy: 0.7083 - loss: 0.8250 - val_accuracy: 0.8482 - val_loss: 17020010.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cbceaab710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# ▶️ Treinamento\n",
    "# ============================================\n",
    "modelo.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    steps_per_epoch=2,\n",
    "    # steps_per_epoch=len(train_gen),\n",
    "    callbacks=[checkpoint, logger],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8593 - loss: 15782828.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AVALIAÇÃO FINAL] Loss: 16016129.0000, Accuracy: 0.8571\n",
      "Salvando modelo final...\n"
     ]
    }
   ],
   "source": [
    "# Avaliação final no conjunto de validação\n",
    "loss, accuracy = modelo.evaluate(val_gen, verbose=1)\n",
    "print(f\"[AVALIAÇÃO FINAL] Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Salvar o modelo final\n",
    "print(\"Salvando modelo final...\")\n",
    "modelo.save(caminho_modelo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
