{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9240ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split # Importar train_test_split\n",
    "from tensorflow.keras.models import load_model # Importar para carregar o modelo da fase 1\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "\n",
    "from core import criar_modelo, ParImageGenerator, create_tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41801b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Nenhuma GPU compat√≠vel detectada. O TensorFlow ser√° executado na CPU.\n",
      "Continuando a execu√ß√£o na CPU.\n"
     ]
    }
   ],
   "source": [
    "# --- Configura√ß√µes Gerais ---\n",
    "# Desative se n√£o estiver depurando para melhor performance em produ√ß√£o\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Configuracao do TensorFlow para usar a GPU, se dispon√≠vel\n",
    "# Verifica se a vari√°vel de ambiente CUDA_VISIBLE_DEVICES est√° definida\n",
    "cuda_visible_devices = os.getenv('CUDA_VISIBLE_DEVICES', None)\n",
    "if cuda_visible_devices is not None:\n",
    "    print(f\"üîß Vari√°vel de ambiente CUDA_VISIBLE_DEVICES definida: {cuda_visible_devices}\")\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        # Configura a mem√≥ria da GPU para crescer dinamicamente, evitando erros de \"Out of Memory\" (OOM)\n",
    "        # ao tentar alocar toda a mem√≥ria da GPU de uma vez.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU(s) detectada(s) e configurada(s) para uso din√¢mico de mem√≥ria: {gpus}\")\n",
    "        print(\"TensorFlow utilizar√° a(s) GPU(s) dispon√≠vel(is).\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma GPU compat√≠vel detectada. O TensorFlow ser√° executado na CPU.\")\n",
    "        # Opcional: Se voc√™ quisesse for√ßar o uso da CPU mesmo com GPU, poderia fazer:\n",
    "        # tf.config.set_visible_devices([], 'GPU') # Esconde todas as GPUs do TensorFlow\n",
    "        print(\"Continuando a execu√ß√£o na CPU.\")\n",
    "except RuntimeError as e:\n",
    "    # Captura erros que podem ocorrer se a GPU n√£o estiver configurada corretamente\n",
    "    print(f\"‚ùå Erro ao configurar GPU: {e}\")\n",
    "    print(\"O TensorFlow ser√° executado na CPU devido ao erro na configura√ß√£o da GPU.\")\n",
    "    # Opcional: Para garantir a CPU ap√≥s um erro, embora TensorFlow fa√ßa isso por padr√£o\n",
    "    # tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209b7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√¢metros para a divis√£o Treino / Valida√ß√£o / Teste (FIXOS)\n",
    "TRAIN_SIZE_RATIO = 0.60 # 60% para o conjunto de treino\n",
    "VAL_SIZE_RATIO = 0.20   # 20% para o conjunto de valida√ß√£o\n",
    "TEST_SIZE_RATIO = 0.20  # 20% para o conjunto de teste\n",
    "\n",
    "GLOBAL_RANDOM_STATE = 42 # Para reprodutibilidade das divis√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22360ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos globais\n",
    "MODEL_DIR = '../model'\n",
    "RESULTS_DIR = '../results'\n",
    "LOGS_DIR = '../logs'\n",
    "CV_LOG_PATH = os.path.join(RESULTS_DIR, 'cv_info.txt')\n",
    "FINAL_TEST_LOG_PATH = os.path.join(RESULTS_DIR, 'final_test_evaluation.txt') # Novo log para teste final\n",
    "IMAGE_TRAINING_DIR = '../image/treinamento'\n",
    "BATCH_SIZE = 8\n",
    "N_SPLITS = 5 # N_SPLITS para o K-Fold (operando apenas no conjunto de treino)\n",
    "KFOLD_RANDOM_STATE = 42 # Random state para o KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2833ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configura√ß√µes das Fases de Treinamento (Hardcoded no script) ---\n",
    "# FASE 1 Treinamento Inicial\n",
    "PHASE1_EPOCHS = 1 # Ajuste para um valor maior (ex: 15-20) para treinamento real\n",
    "PHASE1_LEARNING_RATE = 0.0001\n",
    "PHASE1_ES_PATIENCE = 7\n",
    "PHASE1_CHECKPOINT_FORMAT = f'{MODEL_DIR}/modelo_ph1_fold{{fold}}.h5'\n",
    "PHASE1_HISTORY_LOG_FORMAT = f'{RESULTS_DIR}/historico_fase1_fold{{fold}}.csv'\n",
    "PHASE1_TENSORBOARD_SUFFIX_FORMAT = 'fold_{fold}/fase_1'\n",
    "\n",
    "# FASE 2 Fine-Tuning Aprofundado\n",
    "PHASE2_EPOCHS = 1 # Ajuste para um valor maior (ex: 10-30) para treinamento real\n",
    "PHASE2_LEARNING_RATE = 1e-5 # LR mais baixo para fine-tuning aprofundado\n",
    "PHASE2_ES_PATIENCE = 7\n",
    "PHASE2_CHECKPOINT_FORMAT = f'{MODEL_DIR}/final_tuned_fold{{fold}}.h5'\n",
    "PHASE2_HISTORY_LOG_FORMAT = f'{RESULTS_DIR}/historico_fase2_fold{{fold}}.csv'\n",
    "PHASE2_TENSORBOARD_SUFFIX_FORMAT = 'fold_{fold}/fase_2'\n",
    "PHASE2_FREEZE_LAYERS = 100 # Camadas a congelar na base na Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818c7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cria√ß√£o de Diret√≥rios ---\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c95ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUN√á√ÉO AUXILIAR LOCAL PARA EXECUTAR UMA FASE DE TREINAMENTO ---\n",
    "def _run_training_phase(\n",
    "    model: tf.keras.Model,\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    fold: int,\n",
    "    phase_name: str,\n",
    "    epochs: int,\n",
    "    learning_rate: float,\n",
    "    checkpoint_filepath: str,\n",
    "    history_log_filepath: str,\n",
    "    tensorboard_log_suffix: str,\n",
    "    patience: int\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Executa uma √∫nica fase de treinamento para o modelo, configurando\n",
    "    o compilador e os callbacks com base nas configura√ß√µes da fase.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): O modelo a ser treinado.\n",
    "        train_gen: Gerador de dados de treinamento.\n",
    "        val_gen: Gerador de dados de valida√ß√£o.\n",
    "        fold (int): N√∫mero do fold atual.\n",
    "        phase_name (str): Nome descritivo da fase (e.g., 'Fase 1', 'Fase 2').\n",
    "        epochs (int): N√∫mero de √©pocas.\n",
    "        learning_rate (float): Taxa de aprendizado.\n",
    "        checkpoint_filepath (str): Caminho para salvar o checkpoint do modelo.\n",
    "        history_log_filepath (str): Caminho para o log CSV.\n",
    "        tensorboard_log_suffix (str): Sufixo para o diret√≥rio de logs do TensorBoard.\n",
    "        patience (int): Paci√™ncia para EarlyStopping.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: O modelo ap√≥s o treinamento da fase, com os melhores pesos restaurados pelo EarlyStopping.\n",
    "    \"\"\"\n",
    "    print(f\"--- Iniciando {phase_name} para Fold {fold} ---\")\n",
    "\n",
    "    # Compila o modelo com o learning rate espec√≠fico da fase\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Configura os Callbacks para esta fase\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    logger = CSVLogger(history_log_filepath, append=False)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    tensorboard_callback = create_tensorboard_callback(fold_name=tensorboard_log_suffix)\n",
    "\n",
    "    # Executa o treinamento\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        # steps_per_epoch=len(train_gen),\n",
    "        steps_per_epoch=1,\n",
    "        callbacks=[checkpoint, logger, early_stopping, tensorboard_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"--- {phase_name} para Fold {fold} conclu√≠da ---\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2229097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando todos os dados...\n",
      "Total de pares de imagens carregados: 569\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üîÅ Carregar todos os dados\n",
    "# ============================\n",
    "print(\"Carregando todos os dados...\")\n",
    "gen_temporario = ParImageGenerator(IMAGE_TRAINING_DIR, batch_size=1, augmentacao=False)\n",
    "dados_completos = list(zip(gen_temporario.imagens, gen_temporario.labels))\n",
    "print(f\"Total de pares de imagens carregados: {len(dados_completos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5515673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividindo dados: 60% Treino, 20% Valida√ß√£o, 20% Teste.\n",
      "Pares para Treino (Fixo para K-Fold): 341 (~60%)\n",
      "Pares para Valida√ß√£o (Fixo): 114 (~20%)\n",
      "Pares para Teste (Fixo): 114 (~20%)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üîÅ Divis√£o Treino (60%) / Valida√ß√£o (20%) / Teste (20%) - FIXOS\n",
    "# ============================\n",
    "print(f\"Dividindo dados: {TRAIN_SIZE_RATIO*100:.0f}% Treino, {VAL_SIZE_RATIO*100:.0f}% Valida√ß√£o, {TEST_SIZE_RATIO*100:.0f}% Teste.\")\n",
    "\n",
    "# 1. Separar o conjunto de Teste (20% do total)\n",
    "dados_treino_val_temp, dados_teste_fixo = train_test_split(\n",
    "    dados_completos,\n",
    "    test_size=TEST_SIZE_RATIO,\n",
    "    random_state=GLOBAL_RANDOM_STATE,\n",
    "    stratify=[label for _, label in dados_completos] # Garante propor√ß√£o de classes\n",
    ")\n",
    "\n",
    "# 2. Separar o conjunto de Valida√ß√£o Fixo (20% do total, ou 25% do restante de treino_val_temp)\n",
    "dados_treino_para_kfold, dados_validacao_fixo = train_test_split(\n",
    "    dados_treino_val_temp,\n",
    "    test_size=(VAL_SIZE_RATIO / (TRAIN_SIZE_RATIO + VAL_SIZE_RATIO)), # Calcula a propor√ß√£o para o segundo split (0.20 / 0.80 = 0.25)\n",
    "    random_state=GLOBAL_RANDOM_STATE,\n",
    "    stratify=[label for _, label in dados_treino_val_temp]\n",
    ")\n",
    "\n",
    "print(f\"Pares para Treino (Fixo para K-Fold): {len(dados_treino_para_kfold)} (~{TRAIN_SIZE_RATIO*100:.0f}%)\")\n",
    "print(f\"Pares para Valida√ß√£o (Fixo): {len(dados_validacao_fixo)} (~{VAL_SIZE_RATIO*100:.0f}%)\")\n",
    "print(f\"Pares para Teste (Fixo): {len(dados_teste_fixo)} (~{TEST_SIZE_RATIO*100:.0f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4838e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåÄ Treinando Fold 1 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 1 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_1\\fase_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\cod\\python\\AI\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64s/step - accuracy: 1.0000 - loss: 0.4259\n",
      "Epoch 1: val_loss improved from inf to 0.51185, saving model to ../model/modelo_ph1_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 108s/step - accuracy: 1.0000 - loss: 0.4259 - val_accuracy: 0.8482 - val_loss: 0.5119\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 1 conclu√≠da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "üîß Treinando Fold 1 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 1 n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 1 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_1\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68s/step - accuracy: 0.8750 - loss: 0.4497\n",
      "Epoch 1: val_loss improved from inf to 0.50198, saving model to ../model/final_tuned_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 91s/step - accuracy: 0.8750 - loss: 0.4497 - val_accuracy: 0.8482 - val_loss: 0.5020\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 1 conclu√≠da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 887ms/step - accuracy: 0.8422 - loss: 0.5080\n",
      "üìä [Fold 1] Loss no Valida√ß√£o Fixo: 0.5020, Accuracy no Valida√ß√£o Fixo: 0.8482\n",
      "\n",
      "üåÄ Treinando Fold 2 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 2 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_2\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - accuracy: 0.1250 - loss: 1.1025\n",
      "Epoch 1: val_loss improved from inf to 1.11456, saving model to ../model/modelo_ph1_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80s/step - accuracy: 0.1250 - loss: 1.1025 - val_accuracy: 0.1429 - val_loss: 1.1146\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 2 conclu√≠da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "üîß Treinando Fold 2 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 2 n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 2 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_2\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75s/step - accuracy: 0.6250 - loss: 0.6710\n",
      "Epoch 1: val_loss improved from inf to 1.06511, saving model to ../model/final_tuned_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 119s/step - accuracy: 0.6250 - loss: 0.6710 - val_accuracy: 0.1518 - val_loss: 1.0651\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 2 conclu√≠da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.2406 - loss: 0.9905\n",
      "üìä [Fold 2] Loss no Valida√ß√£o Fixo: 1.0649, Accuracy no Valida√ß√£o Fixo: 0.1518\n",
      "\n",
      "üåÄ Treinando Fold 3 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 3 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_3\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - accuracy: 1.0000 - loss: 0.3395\n",
      "Epoch 1: val_loss improved from inf to 0.49271, saving model to ../model/modelo_ph1_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 105s/step - accuracy: 1.0000 - loss: 0.3395 - val_accuracy: 0.8482 - val_loss: 0.4927\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 3 conclu√≠da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "üîß Treinando Fold 3 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 3 n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 3 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_3\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66s/step - accuracy: 0.8750 - loss: 0.4723\n",
      "Epoch 1: val_loss improved from inf to 0.48436, saving model to ../model/final_tuned_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 102s/step - accuracy: 0.8750 - loss: 0.4723 - val_accuracy: 0.8571 - val_loss: 0.4844\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 3 conclu√≠da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.8325 - loss: 0.5032\n",
      "üìä [Fold 3] Loss no Valida√ß√£o Fixo: 0.4913, Accuracy no Valida√ß√£o Fixo: 0.8482\n",
      "\n",
      "üåÄ Treinando Fold 4 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 4 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_4\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68s/step - accuracy: 0.8750 - loss: 0.4789\n",
      "Epoch 1: val_loss improved from inf to 0.41460, saving model to ../model/modelo_ph1_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 104s/step - accuracy: 0.8750 - loss: 0.4789 - val_accuracy: 0.8571 - val_loss: 0.4146\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 4 conclu√≠da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "üîß Treinando Fold 4 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 4 n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 4 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_4\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - accuracy: 0.7500 - loss: 0.4532\n",
      "Epoch 1: val_loss improved from inf to 0.43120, saving model to ../model/final_tuned_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 106s/step - accuracy: 0.7500 - loss: 0.4532 - val_accuracy: 0.8482 - val_loss: 0.4312\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 4 conclu√≠da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.8041 - loss: 0.5197\n",
      "üìä [Fold 4] Loss no Valida√ß√£o Fixo: 0.4133, Accuracy no Valida√ß√£o Fixo: 0.8571\n",
      "\n",
      "üåÄ Treinando Fold 5 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 5 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_5\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66s/step - accuracy: 0.6250 - loss: 0.6475\n",
      "Epoch 1: val_loss improved from inf to 0.93878, saving model to ../model/modelo_ph1_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 102s/step - accuracy: 0.6250 - loss: 0.6475 - val_accuracy: 0.1518 - val_loss: 0.9388\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 5 conclu√≠da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "üîß Treinando Fold 5 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 5 n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 5 ---\n",
      "‚úÖ Logs do TensorBoard ser√£o salvos em: c:\\cod\\python\\AI\\logs\\fold_5\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67s/step - accuracy: 0.8750 - loss: 0.3096\n",
      "Epoch 1: val_loss improved from inf to 0.93255, saving model to ../model/final_tuned_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 104s/step - accuracy: 0.8750 - loss: 0.3096 - val_accuracy: 0.1518 - val_loss: 0.9325\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 5 conclu√≠da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.1257 - loss: 0.9403\n",
      "üìä [Fold 5] Loss no Valida√ß√£o Fixo: 0.9327, Accuracy no Valida√ß√£o Fixo: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üîÅ K-Fold Cross-Validation NO CONJUNTO DE TREINO FIXO (60%)\n",
    "# ============================\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=KFOLD_RANDOM_STATE)\n",
    "\n",
    "fold = 1\n",
    "# Ac√∫mulo de m√©tricas para a m√©dia do K-Fold (agora, a valida√ß√£o √© sempre no conjunto fixo)\n",
    "accuracies_cv = []\n",
    "losses_cv = []\n",
    "\n",
    "with open(CV_LOG_PATH, 'w') as log_file_cv:\n",
    "    log_file_cv.write(f\"--- Log de Cross-Validation ({N_SPLITS} Folds) ---\\n\")\n",
    "    log_file_cv.write(f\"K-Fold operando no conjunto de Treino Fixo ({len(dados_treino_para_kfold)} pares).\\n\")\n",
    "    log_file_cv.write(f\"Conjunto de Valida√ß√£o Fixo para todos os folds: {len(dados_validacao_fixo)} pares.\\n\\n\")\n",
    "\n",
    "\n",
    "    # Criar o gerador de valida√ß√£o FIXO para TODOS os folds\n",
    "    val_gen_fixo = ParImageGenerator(dados=dados_validacao_fixo, batch_size=BATCH_SIZE, augmentacao=False)\n",
    "\n",
    "\n",
    "    for train_idx_interno, val_idx_interno in kf.split(dados_treino_para_kfold): # K-Fold APENAS no conjunto de treino fixo\n",
    "        log_file_cv.write(f\"[Fold {fold}]\\n\")\n",
    "        log_file_cv.write(f\"√çndices de Treino Interno do Fold: {len(train_idx_interno)} pares\\n\")\n",
    "        log_file_cv.write(f\"√çndices de Valida√ß√£o Interna do Fold (n√£o usado aqui): {len(val_idx_interno)} pares\\n\\n\") # Este val_idx_interno N√ÉO ser√° usado\n",
    "\n",
    "        # Os dados de treinamento para o 'fit' vir√£o apenas do fold de treino\n",
    "        train_data_fold = [dados_treino_para_kfold[i] for i in train_idx_interno]\n",
    "        train_gen_fold = ParImageGenerator(dados=train_data_fold, batch_size=BATCH_SIZE, augmentacao=True)\n",
    "\n",
    "\n",
    "        # --- FASE 1: Fine-tuning Inicial ---\n",
    "        print(f\"\\nüåÄ Treinando Fold {fold} - Fase 1 (Fine-tuning inicial)...\")\n",
    "        modelo_fase1 = criar_modelo() # Cria o modelo para a Fase 1\n",
    "\n",
    "        modelo_fase1_treinado = _run_training_phase(\n",
    "            model=modelo_fase1,\n",
    "            train_gen=train_gen_fold, # Usar o gerador de TREINO do fold\n",
    "            val_gen=val_gen_fixo,   # USAR O GERADOR DE VALIDA√á√ÉO FIXO\n",
    "            fold=fold,\n",
    "            phase_name=\"Fase 1 (Fine-tuning inicial)\",\n",
    "            epochs=PHASE1_EPOCHS,\n",
    "            learning_rate=PHASE1_LEARNING_RATE,\n",
    "            checkpoint_filepath=PHASE1_CHECKPOINT_FORMAT.format(fold=fold),\n",
    "            history_log_filepath=PHASE1_HISTORY_LOG_FORMAT.format(fold=fold),\n",
    "            tensorboard_log_suffix=PHASE1_TENSORBOARD_SUFFIX_FORMAT.format(fold=fold),\n",
    "            patience=PHASE1_ES_PATIENCE\n",
    "        )\n",
    "\n",
    "        # Carregar o melhor modelo da Fase 1 para garantir a continuidade correta\n",
    "        model_path_ph1 = PHASE1_CHECKPOINT_FORMAT.format(fold=fold)\n",
    "        try:\n",
    "            modelo_para_fase2 = load_model(model_path_ph1)\n",
    "            print(f\"‚úÖ Modelo da Fase 1 carregado para a Fase 2.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: N√£o foi poss√≠vel carregar o melhor modelo da Fase 1 para Fold {fold}. Erro: {e}\")\n",
    "            print(\"AVISO: A Fase 2 n√£o poder√° iniciar. Pulando para o pr√≥ximo fold.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # --- FASE 2: Fine-tuning Aprofundado ---\n",
    "        print(f\"\\nüîß Treinando Fold {fold} - Fase 2 (Fine-tuning aprofundado)...\")\n",
    "\n",
    "        # Ajusta as camadas trein√°veis para a Fase 2 (congelando as 100 primeiras)\n",
    "        # O modelo carregado (modelo_para_fase2) √© uma nova inst√¢ncia do modelo original,\n",
    "        # ent√£o suas camadas trein√°veis precisam ser reconfiguradas.\n",
    "        if hasattr(modelo_para_fase2.layers[0], 'layers'):\n",
    "            base_model_ph2 = modelo_para_fase2.layers[0]\n",
    "            base_model_ph2.trainable = True # Garante que a base est√° trein√°vel antes de congelar partes\n",
    "            for layer in base_model_ph2.layers[:PHASE2_FREEZE_LAYERS]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            print(f\"AVISO: A primeira camada do modelo do Fold {fold} n√£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode n√£o funcionar como esperado.\")\n",
    "\n",
    "\n",
    "        modelo_fase2_treinado = _run_training_phase(\n",
    "            model=modelo_para_fase2,\n",
    "            train_gen=train_gen_fold, # Usar o gerador de TREINO do fold\n",
    "            val_gen=val_gen_fixo,   # USAR O GERADOR DE VALIDA√á√ÉO FIXO\n",
    "            fold=fold,\n",
    "            phase_name=\"Fase 2 (Fine-tuning aprofundado)\",\n",
    "            epochs=PHASE2_EPOCHS,\n",
    "            learning_rate=PHASE2_LEARNING_RATE,\n",
    "            checkpoint_filepath=PHASE2_CHECKPOINT_FORMAT.format(fold=fold),\n",
    "            history_log_filepath=PHASE2_HISTORY_LOG_FORMAT.format(fold=fold),\n",
    "            tensorboard_log_suffix=PHASE2_TENSORBOARD_SUFFIX_FORMAT.format(fold=fold),\n",
    "            patience=PHASE2_ES_PATIENCE\n",
    "        )\n",
    "\n",
    "        # Avalia√ß√£o final do modelo da Fase 2 para este fold\n",
    "        # AVALIADO NO CONJUNTO DE VALIDA√á√ÉO FIXO\n",
    "        loss, accuracy = modelo_fase2_treinado.evaluate(val_gen_fixo, verbose=1)\n",
    "        print(f\"üìä [Fold {fold}] Loss no Valida√ß√£o Fixo: {loss:.4f}, Accuracy no Valida√ß√£o Fixo: {accuracy:.4f}\")\n",
    "\n",
    "        log_file_cv.write(f\"Resultado Final Fold {fold} (no Val. Fixo): Loss={loss:.4f}, Accuracy={accuracy:.4f}\\n\\n\")\n",
    "\n",
    "        accuracies_cv.append(accuracy)\n",
    "        losses_cv.append(loss)\n",
    "        fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cce3e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Cross-validation no conjunto de treino finalizada!\n",
      "üìâ M√©dia da Loss (Valida√ß√£o Fixo em CV): 0.6808\n",
      "‚úÖ M√©dia da Accuracy (Valida√ß√£o Fixo em CV): 0.5714\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üìà Resultados de Cross-Validation (no Conjunto de Valida√ß√£o Fixo)\n",
    "# ============================\n",
    "media_acc_cv = np.mean(accuracies_cv)\n",
    "media_loss_cv = np.mean(losses_cv)\n",
    "\n",
    "print(f\"\\n‚úÖ Cross-validation no conjunto de treino finalizada!\")\n",
    "print(f\"üìâ M√©dia da Loss (Valida√ß√£o Fixo em CV): {media_loss_cv:.4f}\")\n",
    "print(f\"‚úÖ M√©dia da Accuracy (Valida√ß√£o Fixo em CV): {media_acc_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32afe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CV_LOG_PATH, 'a') as log_file_cv:\n",
    "    log_file_cv.write(\"=== Resultado Final da Cross-Validation (no Valida√ß√£o Fixo) ===\\n\")\n",
    "    log_file_cv.write(f\"M√©dia da Loss (Valida√ß√£o Fixo em CV): {media_loss_cv:.4f}\\n\")\n",
    "    log_file_cv.write(f\"M√©dia da Accuracy (Valida√ß√£o Fixo em CV): {media_acc_cv:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef70bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Avaliando o modelo final m√©dio no Conjunto de Teste (114 pares)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 673ms/step - accuracy: 0.8265 - loss: 0.5742\n",
      "\n",
      "üéâ Resultado Final no Conjunto de Teste:\n",
      "   Loss no Teste: 0.5606\n",
      "   Accuracy no Teste: 0.8571\n",
      "Resultados do teste final salvos em: ../results\\final_test_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üß™ Avalia√ß√£o Final no Conjunto de Teste Intocado (20% Fixo)\n",
    "# ============================\n",
    "print(f\"\\nüöÄ Avaliando o modelo final m√©dio no Conjunto de Teste ({len(dados_teste_fixo)} pares)...\")\n",
    "\n",
    "MODELO_FINAL_MEDIA_PATH = os.path.join(MODEL_DIR, 'modelo_final_media.h5')\n",
    "\n",
    "try:\n",
    "    final_model_for_test = load_model(MODELO_FINAL_MEDIA_PATH)\n",
    "    test_gen_fixo = ParImageGenerator(dados=dados_teste_fixo, batch_size=BATCH_SIZE, augmentacao=False) # Sem aumento para teste\n",
    "\n",
    "    test_loss, test_accuracy = final_model_for_test.evaluate(test_gen_fixo, verbose=1)\n",
    "\n",
    "    print(f\"\\nüéâ Resultado Final no Conjunto de Teste:\")\n",
    "    print(f\"   Loss no Teste: {test_loss:.4f}\")\n",
    "    print(f\"   Accuracy no Teste: {test_accuracy:.4f}\")\n",
    "\n",
    "    with open(FINAL_TEST_LOG_PATH, 'w') as f_test_log:\n",
    "        f_test_log.write(f\"=== Avalia√ß√£o Final no Conjunto de Teste ===\\n\")\n",
    "        f_test_log.write(f\"Total de pares de teste: {len(dados_teste_fixo)}\\n\")\n",
    "        f_test_log.write(f\"Loss no Teste: {test_loss:.4f}\\n\")\n",
    "        f_test_log.write(f\"Accuracy no Teste: {test_accuracy:.4f}\\n\")\n",
    "    print(f\"Resultados do teste final salvos em: {FINAL_TEST_LOG_PATH}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERRO: O modelo final m√©dio '{MODELO_FINAL_MEDIA_PATH}' n√£o foi encontrado.\")\n",
    "    print(\"Por favor, execute 'python src/modelo_final.py' primeiro para criar o modelo final.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO ao avaliar o modelo final no conjunto de teste: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
