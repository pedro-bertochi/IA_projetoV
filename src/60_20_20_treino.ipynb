{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9240ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split # Importar train_test_split\n",
    "from tensorflow.keras.models import load_model # Importar para carregar o modelo da fase 1\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "\n",
    "from core import criar_modelo, ParImageGenerator, create_tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41801b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Nenhuma GPU compatÃ­vel detectada. O TensorFlow serÃ¡ executado na CPU.\n",
      "Continuando a execuÃ§Ã£o na CPU.\n"
     ]
    }
   ],
   "source": [
    "# --- ConfiguraÃ§Ãµes Gerais ---\n",
    "# Desative se nÃ£o estiver depurando para melhor performance em produÃ§Ã£o\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Configuracao do TensorFlow para usar a GPU, se disponÃ­vel\n",
    "# Verifica se a variÃ¡vel de ambiente CUDA_VISIBLE_DEVICES estÃ¡ definida\n",
    "cuda_visible_devices = os.getenv('CUDA_VISIBLE_DEVICES', None)\n",
    "if cuda_visible_devices is not None:\n",
    "    print(f\"ğŸ”§ VariÃ¡vel de ambiente CUDA_VISIBLE_DEVICES definida: {cuda_visible_devices}\")\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        # Configura a memÃ³ria da GPU para crescer dinamicamente, evitando erros de \"Out of Memory\" (OOM)\n",
    "        # ao tentar alocar toda a memÃ³ria da GPU de uma vez.\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU(s) detectada(s) e configurada(s) para uso dinÃ¢mico de memÃ³ria: {gpus}\")\n",
    "        print(\"TensorFlow utilizarÃ¡ a(s) GPU(s) disponÃ­vel(is).\")\n",
    "    else:\n",
    "        print(\"âŒ Nenhuma GPU compatÃ­vel detectada. O TensorFlow serÃ¡ executado na CPU.\")\n",
    "        # Opcional: Se vocÃª quisesse forÃ§ar o uso da CPU mesmo com GPU, poderia fazer:\n",
    "        # tf.config.set_visible_devices([], 'GPU') # Esconde todas as GPUs do TensorFlow\n",
    "        print(\"Continuando a execuÃ§Ã£o na CPU.\")\n",
    "except RuntimeError as e:\n",
    "    # Captura erros que podem ocorrer se a GPU nÃ£o estiver configurada corretamente\n",
    "    print(f\"âŒ Erro ao configurar GPU: {e}\")\n",
    "    print(\"O TensorFlow serÃ¡ executado na CPU devido ao erro na configuraÃ§Ã£o da GPU.\")\n",
    "    # Opcional: Para garantir a CPU apÃ³s um erro, embora TensorFlow faÃ§a isso por padrÃ£o\n",
    "    # tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209b7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParÃ¢metros para a divisÃ£o Treino / ValidaÃ§Ã£o / Teste (FIXOS)\n",
    "TRAIN_SIZE_RATIO = 0.60 # 60% para o conjunto de treino\n",
    "VAL_SIZE_RATIO = 0.20   # 20% para o conjunto de validaÃ§Ã£o\n",
    "TEST_SIZE_RATIO = 0.20  # 20% para o conjunto de teste\n",
    "\n",
    "GLOBAL_RANDOM_STATE = 42 # Para reprodutibilidade das divisÃµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22360ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos globais\n",
    "MODEL_DIR = '../model'\n",
    "RESULTS_DIR = '../results'\n",
    "LOGS_DIR = '../logs'\n",
    "CV_LOG_PATH = os.path.join(RESULTS_DIR, 'cv_info.txt')\n",
    "FINAL_TEST_LOG_PATH = os.path.join(RESULTS_DIR, 'final_test_evaluation.txt') # Novo log para teste final\n",
    "IMAGE_TRAINING_DIR = '../image/treinamento'\n",
    "BATCH_SIZE = 8\n",
    "N_SPLITS = 5 # N_SPLITS para o K-Fold (operando apenas no conjunto de treino)\n",
    "KFOLD_RANDOM_STATE = 42 # Random state para o KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2833ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ConfiguraÃ§Ãµes das Fases de Treinamento (Hardcoded no script) ---\n",
    "# FASE 1 Treinamento Inicial\n",
    "PHASE1_EPOCHS = 1 # Ajuste para um valor maior (ex: 15-20) para treinamento real\n",
    "PHASE1_LEARNING_RATE = 0.0001\n",
    "PHASE1_ES_PATIENCE = 7\n",
    "PHASE1_CHECKPOINT_FORMAT = f'{MODEL_DIR}/modelo_ph1_fold{{fold}}.h5'\n",
    "PHASE1_HISTORY_LOG_FORMAT = f'{RESULTS_DIR}/historico_fase1_fold{{fold}}.csv'\n",
    "PHASE1_TENSORBOARD_SUFFIX_FORMAT = 'fold_{fold}/fase_1'\n",
    "\n",
    "# FASE 2 Fine-Tuning Aprofundado\n",
    "PHASE2_EPOCHS = 1 # Ajuste para um valor maior (ex: 10-30) para treinamento real\n",
    "PHASE2_LEARNING_RATE = 1e-5 # LR mais baixo para fine-tuning aprofundado\n",
    "PHASE2_ES_PATIENCE = 7\n",
    "PHASE2_CHECKPOINT_FORMAT = f'{MODEL_DIR}/final_tuned_fold{{fold}}.h5'\n",
    "PHASE2_HISTORY_LOG_FORMAT = f'{RESULTS_DIR}/historico_fase2_fold{{fold}}.csv'\n",
    "PHASE2_TENSORBOARD_SUFFIX_FORMAT = 'fold_{fold}/fase_2'\n",
    "PHASE2_FREEZE_LAYERS = 100 # Camadas a congelar na base na Fase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818c7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CriaÃ§Ã£o de DiretÃ³rios ---\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c95ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNÃ‡ÃƒO AUXILIAR LOCAL PARA EXECUTAR UMA FASE DE TREINAMENTO ---\n",
    "def _run_training_phase(\n",
    "    model: tf.keras.Model,\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    fold: int,\n",
    "    phase_name: str,\n",
    "    epochs: int,\n",
    "    learning_rate: float,\n",
    "    checkpoint_filepath: str,\n",
    "    history_log_filepath: str,\n",
    "    tensorboard_log_suffix: str,\n",
    "    patience: int\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Executa uma Ãºnica fase de treinamento para o modelo, configurando\n",
    "    o compilador e os callbacks com base nas configuraÃ§Ãµes da fase.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): O modelo a ser treinado.\n",
    "        train_gen: Gerador de dados de treinamento.\n",
    "        val_gen: Gerador de dados de validaÃ§Ã£o.\n",
    "        fold (int): NÃºmero do fold atual.\n",
    "        phase_name (str): Nome descritivo da fase (e.g., 'Fase 1', 'Fase 2').\n",
    "        epochs (int): NÃºmero de Ã©pocas.\n",
    "        learning_rate (float): Taxa de aprendizado.\n",
    "        checkpoint_filepath (str): Caminho para salvar o checkpoint do modelo.\n",
    "        history_log_filepath (str): Caminho para o log CSV.\n",
    "        tensorboard_log_suffix (str): Sufixo para o diretÃ³rio de logs do TensorBoard.\n",
    "        patience (int): PaciÃªncia para EarlyStopping.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: O modelo apÃ³s o treinamento da fase, com os melhores pesos restaurados pelo EarlyStopping.\n",
    "    \"\"\"\n",
    "    print(f\"--- Iniciando {phase_name} para Fold {fold} ---\")\n",
    "\n",
    "    # Compila o modelo com o learning rate especÃ­fico da fase\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Configura os Callbacks para esta fase\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    logger = CSVLogger(history_log_filepath, append=False)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    tensorboard_callback = create_tensorboard_callback(fold_name=tensorboard_log_suffix)\n",
    "\n",
    "    # Executa o treinamento\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        # steps_per_epoch=len(train_gen),\n",
    "        steps_per_epoch=1,\n",
    "        callbacks=[checkpoint, logger, early_stopping, tensorboard_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"--- {phase_name} para Fold {fold} concluÃ­da ---\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2229097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando todos os dados...\n",
      "Total de pares de imagens carregados: 569\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸ” Carregar todos os dados\n",
    "# ============================\n",
    "print(\"Carregando todos os dados...\")\n",
    "gen_temporario = ParImageGenerator(IMAGE_TRAINING_DIR, batch_size=1, augmentacao=False)\n",
    "dados_completos = list(zip(gen_temporario.imagens, gen_temporario.labels))\n",
    "print(f\"Total de pares de imagens carregados: {len(dados_completos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5515673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividindo dados: 60% Treino, 20% ValidaÃ§Ã£o, 20% Teste.\n",
      "Pares para Treino (Fixo para K-Fold): 341 (~60%)\n",
      "Pares para ValidaÃ§Ã£o (Fixo): 114 (~20%)\n",
      "Pares para Teste (Fixo): 114 (~20%)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸ” DivisÃ£o Treino (60%) / ValidaÃ§Ã£o (20%) / Teste (20%) - FIXOS\n",
    "# ============================\n",
    "print(f\"Dividindo dados: {TRAIN_SIZE_RATIO*100:.0f}% Treino, {VAL_SIZE_RATIO*100:.0f}% ValidaÃ§Ã£o, {TEST_SIZE_RATIO*100:.0f}% Teste.\")\n",
    "\n",
    "# 1. Separar o conjunto de Teste (20% do total)\n",
    "dados_treino_val_temp, dados_teste_fixo = train_test_split(\n",
    "    dados_completos,\n",
    "    test_size=TEST_SIZE_RATIO,\n",
    "    random_state=GLOBAL_RANDOM_STATE,\n",
    "    stratify=[label for _, label in dados_completos] # Garante proporÃ§Ã£o de classes\n",
    ")\n",
    "\n",
    "# 2. Separar o conjunto de ValidaÃ§Ã£o Fixo (20% do total, ou 25% do restante de treino_val_temp)\n",
    "dados_treino_para_kfold, dados_validacao_fixo = train_test_split(\n",
    "    dados_treino_val_temp,\n",
    "    test_size=(VAL_SIZE_RATIO / (TRAIN_SIZE_RATIO + VAL_SIZE_RATIO)), # Calcula a proporÃ§Ã£o para o segundo split (0.20 / 0.80 = 0.25)\n",
    "    random_state=GLOBAL_RANDOM_STATE,\n",
    "    stratify=[label for _, label in dados_treino_val_temp]\n",
    ")\n",
    "\n",
    "print(f\"Pares para Treino (Fixo para K-Fold): {len(dados_treino_para_kfold)} (~{TRAIN_SIZE_RATIO*100:.0f}%)\")\n",
    "print(f\"Pares para ValidaÃ§Ã£o (Fixo): {len(dados_validacao_fixo)} (~{VAL_SIZE_RATIO*100:.0f}%)\")\n",
    "print(f\"Pares para Teste (Fixo): {len(dados_teste_fixo)} (~{TEST_SIZE_RATIO*100:.0f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4838e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Treinando Fold 1 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 1 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_1\\fase_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\cod\\python\\AI\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64s/step - accuracy: 1.0000 - loss: 0.4259\n",
      "Epoch 1: val_loss improved from inf to 0.51185, saving model to ../model/modelo_ph1_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 108s/step - accuracy: 1.0000 - loss: 0.4259 - val_accuracy: 0.8482 - val_loss: 0.5119\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 1 concluÃ­da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "ğŸ”§ Treinando Fold 1 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 1 nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 1 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_1\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68s/step - accuracy: 0.8750 - loss: 0.4497\n",
      "Epoch 1: val_loss improved from inf to 0.50198, saving model to ../model/final_tuned_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 91s/step - accuracy: 0.8750 - loss: 0.4497 - val_accuracy: 0.8482 - val_loss: 0.5020\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 1 concluÃ­da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 887ms/step - accuracy: 0.8422 - loss: 0.5080\n",
      "ğŸ“Š [Fold 1] Loss no ValidaÃ§Ã£o Fixo: 0.5020, Accuracy no ValidaÃ§Ã£o Fixo: 0.8482\n",
      "\n",
      "ğŸŒ€ Treinando Fold 2 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 2 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_2\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - accuracy: 0.1250 - loss: 1.1025\n",
      "Epoch 1: val_loss improved from inf to 1.11456, saving model to ../model/modelo_ph1_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80s/step - accuracy: 0.1250 - loss: 1.1025 - val_accuracy: 0.1429 - val_loss: 1.1146\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 2 concluÃ­da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "ğŸ”§ Treinando Fold 2 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 2 nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 2 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_2\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75s/step - accuracy: 0.6250 - loss: 0.6710\n",
      "Epoch 1: val_loss improved from inf to 1.06511, saving model to ../model/final_tuned_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 119s/step - accuracy: 0.6250 - loss: 0.6710 - val_accuracy: 0.1518 - val_loss: 1.0651\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 2 concluÃ­da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.2406 - loss: 0.9905\n",
      "ğŸ“Š [Fold 2] Loss no ValidaÃ§Ã£o Fixo: 1.0649, Accuracy no ValidaÃ§Ã£o Fixo: 0.1518\n",
      "\n",
      "ğŸŒ€ Treinando Fold 3 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 3 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_3\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - accuracy: 1.0000 - loss: 0.3395\n",
      "Epoch 1: val_loss improved from inf to 0.49271, saving model to ../model/modelo_ph1_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 105s/step - accuracy: 1.0000 - loss: 0.3395 - val_accuracy: 0.8482 - val_loss: 0.4927\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 3 concluÃ­da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "ğŸ”§ Treinando Fold 3 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 3 nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 3 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_3\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66s/step - accuracy: 0.8750 - loss: 0.4723\n",
      "Epoch 1: val_loss improved from inf to 0.48436, saving model to ../model/final_tuned_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 102s/step - accuracy: 0.8750 - loss: 0.4723 - val_accuracy: 0.8571 - val_loss: 0.4844\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 3 concluÃ­da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.8325 - loss: 0.5032\n",
      "ğŸ“Š [Fold 3] Loss no ValidaÃ§Ã£o Fixo: 0.4913, Accuracy no ValidaÃ§Ã£o Fixo: 0.8482\n",
      "\n",
      "ğŸŒ€ Treinando Fold 4 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 4 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_4\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68s/step - accuracy: 0.8750 - loss: 0.4789\n",
      "Epoch 1: val_loss improved from inf to 0.41460, saving model to ../model/modelo_ph1_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 104s/step - accuracy: 0.8750 - loss: 0.4789 - val_accuracy: 0.8571 - val_loss: 0.4146\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 4 concluÃ­da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "ğŸ”§ Treinando Fold 4 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 4 nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 4 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_4\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69s/step - accuracy: 0.7500 - loss: 0.4532\n",
      "Epoch 1: val_loss improved from inf to 0.43120, saving model to ../model/final_tuned_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 106s/step - accuracy: 0.7500 - loss: 0.4532 - val_accuracy: 0.8482 - val_loss: 0.4312\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 4 concluÃ­da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.8041 - loss: 0.5197\n",
      "ğŸ“Š [Fold 4] Loss no ValidaÃ§Ã£o Fixo: 0.4133, Accuracy no ValidaÃ§Ã£o Fixo: 0.8571\n",
      "\n",
      "ğŸŒ€ Treinando Fold 5 - Fase 1 (Fine-tuning inicial)...\n",
      "--- Iniciando Fase 1 (Fine-tuning inicial) para Fold 5 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_5\\fase_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66s/step - accuracy: 0.6250 - loss: 0.6475\n",
      "Epoch 1: val_loss improved from inf to 0.93878, saving model to ../model/modelo_ph1_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 102s/step - accuracy: 0.6250 - loss: 0.6475 - val_accuracy: 0.1518 - val_loss: 0.9388\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 1 (Fine-tuning inicial) para Fold 5 concluÃ­da ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo da Fase 1 carregado para a Fase 2.\n",
      "\n",
      "ğŸ”§ Treinando Fold 5 - Fase 2 (Fine-tuning aprofundado)...\n",
      "AVISO: A primeira camada do modelo do Fold 5 nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\n",
      "--- Iniciando Fase 2 (Fine-tuning aprofundado) para Fold 5 ---\n",
      "âœ… Logs do TensorBoard serÃ£o salvos em: c:\\cod\\python\\AI\\logs\\fold_5\\fase_2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67s/step - accuracy: 0.8750 - loss: 0.3096\n",
      "Epoch 1: val_loss improved from inf to 0.93255, saving model to ../model/final_tuned_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 104s/step - accuracy: 0.8750 - loss: 0.3096 - val_accuracy: 0.1518 - val_loss: 0.9325\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "--- Fase 2 (Fine-tuning aprofundado) para Fold 5 concluÃ­da ---\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.1257 - loss: 0.9403\n",
      "ğŸ“Š [Fold 5] Loss no ValidaÃ§Ã£o Fixo: 0.9327, Accuracy no ValidaÃ§Ã£o Fixo: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸ” K-Fold Cross-Validation NO CONJUNTO DE TREINO FIXO (60%)\n",
    "# ============================\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=KFOLD_RANDOM_STATE)\n",
    "\n",
    "fold = 1\n",
    "# AcÃºmulo de mÃ©tricas para a mÃ©dia do K-Fold (agora, a validaÃ§Ã£o Ã© sempre no conjunto fixo)\n",
    "accuracies_cv = []\n",
    "losses_cv = []\n",
    "\n",
    "with open(CV_LOG_PATH, 'w') as log_file_cv:\n",
    "    log_file_cv.write(f\"--- Log de Cross-Validation ({N_SPLITS} Folds) ---\\n\")\n",
    "    log_file_cv.write(f\"K-Fold operando no conjunto de Treino Fixo ({len(dados_treino_para_kfold)} pares).\\n\")\n",
    "    log_file_cv.write(f\"Conjunto de ValidaÃ§Ã£o Fixo para todos os folds: {len(dados_validacao_fixo)} pares.\\n\\n\")\n",
    "\n",
    "\n",
    "    # Criar o gerador de validaÃ§Ã£o FIXO para TODOS os folds\n",
    "    val_gen_fixo = ParImageGenerator(dados=dados_validacao_fixo, batch_size=BATCH_SIZE, augmentacao=False)\n",
    "\n",
    "\n",
    "    for train_idx_interno, val_idx_interno in kf.split(dados_treino_para_kfold): # K-Fold APENAS no conjunto de treino fixo\n",
    "        log_file_cv.write(f\"[Fold {fold}]\\n\")\n",
    "        log_file_cv.write(f\"Ãndices de Treino Interno do Fold: {len(train_idx_interno)} pares\\n\")\n",
    "        log_file_cv.write(f\"Ãndices de ValidaÃ§Ã£o Interna do Fold (nÃ£o usado aqui): {len(val_idx_interno)} pares\\n\\n\") # Este val_idx_interno NÃƒO serÃ¡ usado\n",
    "\n",
    "        # Os dados de treinamento para o 'fit' virÃ£o apenas do fold de treino\n",
    "        train_data_fold = [dados_treino_para_kfold[i] for i in train_idx_interno]\n",
    "        train_gen_fold = ParImageGenerator(dados=train_data_fold, batch_size=BATCH_SIZE, augmentacao=True)\n",
    "\n",
    "\n",
    "        # --- FASE 1: Fine-tuning Inicial ---\n",
    "        print(f\"\\nğŸŒ€ Treinando Fold {fold} - Fase 1 (Fine-tuning inicial)...\")\n",
    "        modelo_fase1 = criar_modelo() # Cria o modelo para a Fase 1\n",
    "\n",
    "        modelo_fase1_treinado = _run_training_phase(\n",
    "            model=modelo_fase1,\n",
    "            train_gen=train_gen_fold, # Usar o gerador de TREINO do fold\n",
    "            val_gen=val_gen_fixo,   # USAR O GERADOR DE VALIDAÃ‡ÃƒO FIXO\n",
    "            fold=fold,\n",
    "            phase_name=\"Fase 1 (Fine-tuning inicial)\",\n",
    "            epochs=PHASE1_EPOCHS,\n",
    "            learning_rate=PHASE1_LEARNING_RATE,\n",
    "            checkpoint_filepath=PHASE1_CHECKPOINT_FORMAT.format(fold=fold),\n",
    "            history_log_filepath=PHASE1_HISTORY_LOG_FORMAT.format(fold=fold),\n",
    "            tensorboard_log_suffix=PHASE1_TENSORBOARD_SUFFIX_FORMAT.format(fold=fold),\n",
    "            patience=PHASE1_ES_PATIENCE\n",
    "        )\n",
    "\n",
    "        # Carregar o melhor modelo da Fase 1 para garantir a continuidade correta\n",
    "        model_path_ph1 = PHASE1_CHECKPOINT_FORMAT.format(fold=fold)\n",
    "        try:\n",
    "            modelo_para_fase2 = load_model(model_path_ph1)\n",
    "            print(f\"âœ… Modelo da Fase 1 carregado para a Fase 2.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AVISO: NÃ£o foi possÃ­vel carregar o melhor modelo da Fase 1 para Fold {fold}. Erro: {e}\")\n",
    "            print(\"AVISO: A Fase 2 nÃ£o poderÃ¡ iniciar. Pulando para o prÃ³ximo fold.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # --- FASE 2: Fine-tuning Aprofundado ---\n",
    "        print(f\"\\nğŸ”§ Treinando Fold {fold} - Fase 2 (Fine-tuning aprofundado)...\")\n",
    "\n",
    "        # Ajusta as camadas treinÃ¡veis para a Fase 2 (congelando as 100 primeiras)\n",
    "        # O modelo carregado (modelo_para_fase2) Ã© uma nova instÃ¢ncia do modelo original,\n",
    "        # entÃ£o suas camadas treinÃ¡veis precisam ser reconfiguradas.\n",
    "        if hasattr(modelo_para_fase2.layers[0], 'layers'):\n",
    "            base_model_ph2 = modelo_para_fase2.layers[0]\n",
    "            base_model_ph2.trainable = True # Garante que a base estÃ¡ treinÃ¡vel antes de congelar partes\n",
    "            for layer in base_model_ph2.layers[:PHASE2_FREEZE_LAYERS]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            print(f\"AVISO: A primeira camada do modelo do Fold {fold} nÃ£o parece ser a base ResNet50. Fine-tuning da Fase 2 pode nÃ£o funcionar como esperado.\")\n",
    "\n",
    "\n",
    "        modelo_fase2_treinado = _run_training_phase(\n",
    "            model=modelo_para_fase2,\n",
    "            train_gen=train_gen_fold, # Usar o gerador de TREINO do fold\n",
    "            val_gen=val_gen_fixo,   # USAR O GERADOR DE VALIDAÃ‡ÃƒO FIXO\n",
    "            fold=fold,\n",
    "            phase_name=\"Fase 2 (Fine-tuning aprofundado)\",\n",
    "            epochs=PHASE2_EPOCHS,\n",
    "            learning_rate=PHASE2_LEARNING_RATE,\n",
    "            checkpoint_filepath=PHASE2_CHECKPOINT_FORMAT.format(fold=fold),\n",
    "            history_log_filepath=PHASE2_HISTORY_LOG_FORMAT.format(fold=fold),\n",
    "            tensorboard_log_suffix=PHASE2_TENSORBOARD_SUFFIX_FORMAT.format(fold=fold),\n",
    "            patience=PHASE2_ES_PATIENCE\n",
    "        )\n",
    "\n",
    "        # AvaliaÃ§Ã£o final do modelo da Fase 2 para este fold\n",
    "        # AVALIADO NO CONJUNTO DE VALIDAÃ‡ÃƒO FIXO\n",
    "        loss, accuracy = modelo_fase2_treinado.evaluate(val_gen_fixo, verbose=1)\n",
    "        print(f\"ğŸ“Š [Fold {fold}] Loss no ValidaÃ§Ã£o Fixo: {loss:.4f}, Accuracy no ValidaÃ§Ã£o Fixo: {accuracy:.4f}\")\n",
    "\n",
    "        log_file_cv.write(f\"Resultado Final Fold {fold} (no Val. Fixo): Loss={loss:.4f}, Accuracy={accuracy:.4f}\\n\\n\")\n",
    "\n",
    "        accuracies_cv.append(accuracy)\n",
    "        losses_cv.append(loss)\n",
    "        fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cce3e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Cross-validation no conjunto de treino finalizada!\n",
      "ğŸ“‰ MÃ©dia da Loss (ValidaÃ§Ã£o Fixo em CV): 0.6808\n",
      "âœ… MÃ©dia da Accuracy (ValidaÃ§Ã£o Fixo em CV): 0.5714\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸ“ˆ Resultados de Cross-Validation (no Conjunto de ValidaÃ§Ã£o Fixo)\n",
    "# ============================\n",
    "media_acc_cv = np.mean(accuracies_cv)\n",
    "media_loss_cv = np.mean(losses_cv)\n",
    "\n",
    "print(f\"\\nâœ… Cross-validation no conjunto de treino finalizada!\")\n",
    "print(f\"ğŸ“‰ MÃ©dia da Loss (ValidaÃ§Ã£o Fixo em CV): {media_loss_cv:.4f}\")\n",
    "print(f\"âœ… MÃ©dia da Accuracy (ValidaÃ§Ã£o Fixo em CV): {media_acc_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32afe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CV_LOG_PATH, 'a') as log_file_cv:\n",
    "    log_file_cv.write(\"=== Resultado Final da Cross-Validation (no ValidaÃ§Ã£o Fixo) ===\\n\")\n",
    "    log_file_cv.write(f\"MÃ©dia da Loss (ValidaÃ§Ã£o Fixo em CV): {media_loss_cv:.4f}\\n\")\n",
    "    log_file_cv.write(f\"MÃ©dia da Accuracy (ValidaÃ§Ã£o Fixo em CV): {media_acc_cv:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef70bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Avaliando o modelo final mÃ©dio no Conjunto de Teste (114 pares)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 673ms/step - accuracy: 0.8265 - loss: 0.5742\n",
      "\n",
      "ğŸ‰ Resultado Final no Conjunto de Teste:\n",
      "   Loss no Teste: 0.5606\n",
      "   Accuracy no Teste: 0.8571\n",
      "Resultados do teste final salvos em: ../results\\final_test_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ğŸ§ª AvaliaÃ§Ã£o Final no Conjunto de Teste Intocado (20% Fixo)\n",
    "# ============================\n",
    "print(f\"\\nğŸš€ Avaliando o modelo final mÃ©dio no Conjunto de Teste ({len(dados_teste_fixo)} pares)...\")\n",
    "\n",
    "MODELO_FINAL_MEDIA_PATH = os.path.join(MODEL_DIR, 'modelo_final_media.h5')\n",
    "\n",
    "try:\n",
    "    final_model_for_test = load_model(MODELO_FINAL_MEDIA_PATH)\n",
    "    test_gen_fixo = ParImageGenerator(dados=dados_teste_fixo, batch_size=BATCH_SIZE, augmentacao=False) # Sem aumento para teste\n",
    "\n",
    "    test_loss, test_accuracy = final_model_for_test.evaluate(test_gen_fixo, verbose=1)\n",
    "\n",
    "    print(f\"\\nğŸ‰ Resultado Final no Conjunto de Teste:\")\n",
    "    print(f\"   Loss no Teste: {test_loss:.4f}\")\n",
    "    print(f\"   Accuracy no Teste: {test_accuracy:.4f}\")\n",
    "\n",
    "    with open(FINAL_TEST_LOG_PATH, 'w') as f_test_log:\n",
    "        f_test_log.write(f\"=== AvaliaÃ§Ã£o Final no Conjunto de Teste ===\\n\")\n",
    "        f_test_log.write(f\"Total de pares de teste: {len(dados_teste_fixo)}\\n\")\n",
    "        f_test_log.write(f\"Loss no Teste: {test_loss:.4f}\\n\")\n",
    "        f_test_log.write(f\"Accuracy no Teste: {test_accuracy:.4f}\\n\")\n",
    "    print(f\"Resultados do teste final salvos em: {FINAL_TEST_LOG_PATH}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ERRO: O modelo final mÃ©dio '{MODELO_FINAL_MEDIA_PATH}' nÃ£o foi encontrado.\")\n",
    "    print(\"Por favor, execute 'python src/modelo_final.py' primeiro para criar o modelo final.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERRO ao avaliar o modelo final no conjunto de teste: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
